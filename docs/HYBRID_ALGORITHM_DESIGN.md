# Dise√±o del Algoritmo H√≠brido HybridDPMeta

## 1. Motivaci√≥n y Contexto

### Problema
- **DP es exacto pero lento**: O(k¬≤ ¬∑ 3^n) - solo pr√°ctico para n ‚â§ 15
- **Metaheur√≠sticas son r√°pidas pero no √≥ptimas**: No tienen garant√≠as te√≥ricas
- **Necesidad**: Un algoritmo que combine lo mejor de ambos mundos

### Idea Central
Dividir el problema en dos fases:
1. **Fase R√°pida (Metaheur√≠stica)**: Asignar un porcentaje de √≠tems r√°pidamente
2. **Fase Exacta (DP)**: Resolver el subproblema restante de forma √≥ptima

## 2. Dise√±o del Algoritmo HybridDPMeta

### Par√°metros Clave
- `dp_threshold`: N√∫mero m√°ximo de √≠tems que DP puede manejar eficientemente (default: 12)
- `meta_algorithm`: Metaheur√≠stica a usar ('simulated_annealing', 'genetic', 'tabu')
- `partition_strategy`: C√≥mo dividir los √≠tems ('largest_first', 'random', 'clustering')
- `quality_weight`: Peso para balance calidad/tiempo en selecci√≥n de estrategia

### Estrategias de Partici√≥n

#### 2.1 Largest First (Recomendada)
Asignar primero los √≠tems m√°s grandes con metaheur√≠stica:
- √çtems grandes tienen mayor impacto en el balance
- Dejar √≠tems peque√±os para DP permite ajuste fino
- Justificaci√≥n: Los √≠tems peque√±os son m√°s f√°ciles de "encajar" √≥ptimamente

#### 2.2 Value-Based
Asignar √≠tems por valor:
- √çtems de alto valor primero (metaheur√≠stica)
- √çtems de bajo valor despu√©s (DP para ajuste fino del balance)

#### 2.3 Clustering
Agrupar √≠tems similares:
- Crear clusters por peso/valor
- Asignar clusters grandes con meta, individuales con DP

### Pseudoc√≥digo

```
ALGORITHM HybridDPMeta(items, bins, dp_threshold=12):
    n = |items|
    k = |bins|
    
    IF n <= dp_threshold:
        RETURN DP.solve(items, bins)  # Exacto para instancias peque√±as
    
    # Fase 1: Partici√≥n de √≠tems
    n_meta = n - dp_threshold  # √çtems para metaheur√≠stica
    n_dp = dp_threshold        # √çtems para DP
    
    meta_items, dp_items = partition_items(items, n_meta, strategy)
    
    # Fase 2: Resolver con metaheur√≠stica
    # Crear problema parcial con todos los bins pero solo meta_items
    partial_problem = Problem(meta_items, bins)
    meta_solution = Metaheuristic.solve(partial_problem)
    
    # Fase 3: Calcular capacidades residuales
    residual_capacities = []
    FOR j = 1 TO k:
        used_weight = sum(item.weight for item in meta_solution.bins[j])
        residual = bins[j].capacity - used_weight
        residual_capacities.append(residual)
    
    # Fase 4: Resolver subproblema exactamente
    # dp_items debe asignarse a bins con capacidades residuales
    residual_problem = Problem(dp_items, bins_with_residual_capacities)
    dp_solution = DP.solve(residual_problem)
    
    # Fase 5: Combinar soluciones
    final_solution = merge_solutions(meta_solution, dp_solution)
    
    RETURN final_solution
```

### Optimizaciones

1. **Adaptive Threshold**: Ajustar dp_threshold basado en k y tiempo disponible
2. **Early Termination**: Si metaheur√≠stica encuentra soluci√≥n muy buena, no usar DP
3. **Iterative Refinement**: Permitir m√∫ltiples iteraciones meta‚ÜíDP
4. **Caching**: Cache de subproblemas DP para problemas similares

## 3. Framework de Experimentaci√≥n

### Dise√±o Experimental

#### Variables Independientes
- Tama√±o del problema (n): [15, 20, 25, 30, 40, 50, 75, 100]
- N√∫mero de bins (k): [2, 3, 4, 5]
- Tipo de distribuci√≥n: [uniform, normal, correlated, clustered]
- Variaci√≥n de capacidad: [0, 0.2, 0.4]

#### Variables Dependientes
- Calidad de soluci√≥n (objetivo: max-min)
- Tiempo de ejecuci√≥n
- Gap de optimalidad (para instancias peque√±as con soluci√≥n conocida)

#### M√©tricas Compuestas
- **Score Ponderado**: Œ± √ó (1 - normalized_objective) + (1-Œ±) √ó (1 - normalized_time)
- **Ratio Calidad/Tiempo**: objective_improvement / time_increase

### Pruebas Estad√≠sticas

#### 1. Comparaci√≥n de Medianas (Mann-Whitney U)
- H0: No hay diferencia entre algoritmos
- H1: H√≠brido es mejor
- Œ± = 0.05

#### 2. Comparaci√≥n de Medias (t-Student pareado)
- Para distribuciones normales
- Test de normalidad previo (Shapiro-Wilk)

#### 3. An√°lisis de Varianza (ANOVA)
- Comparar m√∫ltiples algoritmos simult√°neamente
- Post-hoc: Tukey HSD

#### 4. Efecto del Tama√±o (Cohen's d)
- Medir magnitud del efecto, no solo significancia

### N√∫mero de Repeticiones
- M√≠nimo 30 repeticiones por configuraci√≥n (CLT)
- 50 repeticiones para alta confiabilidad
- Seeds fijos para reproducibilidad

## 4. Estructura de Archivos

```
discrete_logistics/
‚îú‚îÄ‚îÄ algorithms/
‚îÇ   ‚îî‚îÄ‚îÄ hybrid.py                 # Algoritmo h√≠brido
‚îú‚îÄ‚îÄ benchmarks/
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_experiment.py      # Framework experimental
‚îÇ   ‚îú‚îÄ‚îÄ statistical_tests.py      # Tests estad√≠sticos
‚îÇ   ‚îî‚îÄ‚îÄ results/
‚îÇ       ‚îî‚îÄ‚îÄ hybrid/               # Resultados del h√≠brido
‚îÇ           ‚îú‚îÄ‚îÄ raw_results.csv
‚îÇ           ‚îú‚îÄ‚îÄ statistical_analysis.json
‚îÇ           ‚îî‚îÄ‚îÄ figures/
‚îî‚îÄ‚îÄ dashboard/
    ‚îî‚îÄ‚îÄ pages/
        ‚îî‚îÄ‚îÄ 5_üß¨_Algoritmo_Hibrido.py  # P√°gina especial
```

## 5. M√©tricas de √âxito

1. **Calidad**: H√≠brido debe tener gap < 5% respecto a DP en instancias peque√±as
2. **Velocidad**: H√≠brido debe ser >10x m√°s r√°pido que DP para n > 20
3. **Escalabilidad**: H√≠brido debe manejar n = 100 en < 60 segundos
4. **Robustez**: Resultados consistentes (bajo CV) en m√∫ltiples repeticiones
5. **Estad√≠stica**: p-value < 0.05 en comparaciones con otros algoritmos

## 6. Plan de Implementaci√≥n

### Fase 1: Algoritmo Base (D√≠a 1)
- [ ] Implementar clase HybridDPMeta
- [ ] Estrategias de partici√≥n
- [ ] Integraci√≥n con DP y SA existentes

### Fase 2: Experimentaci√≥n (D√≠a 2)
- [ ] Framework de benchmarking
- [ ] Generaci√≥n de instancias variadas
- [ ] Ejecuci√≥n paralela de experimentos

### Fase 3: An√°lisis Estad√≠stico (D√≠a 2-3)
- [ ] Implementar tests estad√≠sticos
- [ ] An√°lisis de resultados
- [ ] Visualizaciones

### Fase 4: Dashboard (D√≠a 3)
- [ ] P√°gina interactiva
- [ ] Gr√°ficos exportables
- [ ] Documentaci√≥n integrada
